{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.10"},"colab":{"name":"Copy of Preprocessing_data,_Data_modelling_and_Interpretability.ipynb","provenance":[{"file_id":"15pptniOtcAHieDFKv3xyCc2Rbo_HbFzm","timestamp":1641747267292}],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"MPcJDXmkgRNI"},"source":["Index <br>\n","1) Processing data <br>\n","2) Training and validation <br>\n","3) Interprertability"]},{"cell_type":"markdown","metadata":{"id":"6Hfi7ZoQgRNJ"},"source":["## 1. Preprocessing data"]},{"cell_type":"markdown","metadata":{"id":"ajRpIa70gRNJ"},"source":["## 1.1 Prepare a csv file with \"sentence id\", \"sentence\", \"label\" as features\n","\n","Following is the script:<br>\n","Origin file: <b>paper/aesw_to_sentences.py</b>"]},{"cell_type":"code","metadata":{"id":"MW5drUJJgRNK"},"source":["import argparse\n","import csv\n","import heapq\n","import os\n","from pathlib import Path\n","from typing import List, Tuple\n","import pandas as pda\n","from lxml import etree\n","from tqdm import tqdm\n","import numpy as np\n","\n","\n","def extract_sentence(sent_elem: etree._Element) -> str:\n","    '''\n","     extract sentence from the xml.\n","    '''\n","    assert sent_elem.tag == \"sentence\"\n","    string_builder = [str(sent_elem.text) if sent_elem.text else \"\"]\n","    for del_ins in sent_elem:\n","        if del_ins.tag == \"del\" and del_ins.text:\n","            string_builder.append(str(del_ins.text))\n","        if del_ins.tail:\n","            string_builder.append(str(del_ins.tail))\n","    return \"\".join(string_builder)\n","\n","\n","def extract_sentence_after_editing(sent_elem: etree._Element) -> str:\n","    '''\n","     extract part of the sentence after editing.\n","    '''\n","    assert sent_elem.tag == \"sentence\"\n","    string_builder = [str(sent_elem.text) if sent_elem.text else \"\"]\n","\n","    for del_ins in sent_elem:\n","        if del_ins.tag == \"ins\" and del_ins.text:\n","            string_builder.append(str(del_ins.text))\n","        if del_ins.tail:\n","            string_builder.append(str(del_ins.tail))\n","\n","    return \"\".join(string_builder)\n","\n","\n","def extract_sentence_id(sent_elem: etree._Element) -> str:\n","    '''\n","     extract sentence id \n","    '''\n","    assert sent_elem.tag == \"sentence\"\n","    assert \"sid\" in sent_elem.attrib\n","    return str(sent_elem.attrib[\"sid\"])\n","\n","\n","def get_label(sent_elem: etree._Element) -> int:\n","    \"\"\"\n","    0 if no edit/no change, 1 if changed/edited\n","    \"\"\"\n","    return 1 if len(list(sent_elem)) > 0 else 0\n","\n","\n","def read_xml(xml_filepath: Path, output_filepath: Path) -> None:\n","    if os.path.isfile(output_filepath):\n","        os.remove(output_filepath)\n","\n","    with open(output_filepath, \"w\") as file:\n","        writer = csv.writer(file)\n","        writer.writerow([\"id\", \"sentence\", \"label\"])\n","\n","    sentences: List[Tuple[int, str, str, int]] = []\n","\n","    for event, sent_elem in tqdm(etree.iterparse(str(xml_filepath), tag=\"sentence\")):\n","        sent_id = extract_sentence_id(sent_elem)\n","        sent = extract_sentence(sent_elem)\n","        heapq.heappush(sentences, (len(sent), sent_id, sent, get_label(sent_elem)))\n","\n","    with open(output_filepath, \"a\") as file:\n","        writer = csv.writer(file)\n","        while sentences:\n","            _, identifier, sent, label = heapq.heappop(sentences)\n","            writer.writerow((identifier, sent, label))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"662IOJdZgRNL"},"source":["# Call to preprocess\n","\n","# for test data\n","test_xml = Path(\"./data-unversioned/aesw/aesw2016(v1.2)_test_modified.xml\")\n","test_out = Path(\"./data-unversioned/aesw/aesw-test.csv\")\n","read_xml(test_xml, test_out)\n","\n","# for dev data\n","dev_xml = Path(\"./data-unversioned/aesw/aesw2016(v1.2)_dev.xml\")\n","dev_out = Path(\"./data-unversioned/aesw/aesw-dev.csv\")\n","read_xml(dev_xml, dev_out)\n","\n","# for train data\n","train_xml = Path(\"./data-unversioned/aesw/aesw2016(v1.2)_train.xml\")\n","train_out = Path(\"./data-unversioned/aesw/aesw-train.csv\")\n","read_xml(train_xml, train_out)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Fwes-q-6gRNL"},"source":["## 1.2 Tokeize the data and store in pickle file \n","\n","Following is the script:"]},{"cell_type":"code","metadata":{"id":"TNS2zKUggRNM"},"source":["import bisect\n","import os\n","import pickle\n","import random\n","import shutil\n","from pathlib import Path\n","from typing import Iterator, List, Optional, Tuple, cast, Set\n","\n","import torch\n","from torch import Tensor\n","from torch.utils.data import DataLoader, Sampler, Subset, TensorDataset\n","from transformers import PreTrainedTokenizerFast"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NRywBws6gRNM"},"source":["# Hperparameter class\n","# origin file: paper/structures.py\n","\n","from dataclasses import dataclass\n","import toml\n","from typing_extensions import Literal\n","\n","\n","class HyperParameters:\n","    '''\n","     initialize training, validation, test folders and other file path and variables used while training\n","     \n","    '''\n","    batch_size: int\n","    learning_rate: float\n","    epochs_in_12_hours: int\n","    train_file: Optional[Path]\n","    train_folder: Optional[Path]\n","    train_preprocessed_folder: Path\n","    val_file: Path\n","    val_preprocessed_folder: Path\n","    test_file: Path\n","    test_preprocessed_folder: Path\n","    model_name: str\n","    root_model_name: Optional[str]\n","    tokenizer_name: str\n","    models_dir: Path\n","    experiment_name: str\n","    checkpoint_interval: float\n","    vocab_size: int\n","    checkpoint_csv: Path\n","\n","    def __init__(self, toml_filepath: str) -> None:\n","        parsed = toml.load([toml_filepath])\n","\n","        self.batch_size = int(parsed[\"batch_size\"])\n","        self.learning_rate = float(parsed[\"learning_rate\"])\n","        self.max_epochs = int(parsed[\"max_epochs\"])\n","        self.model_name = parsed[\"model_name\"]\n","        self.tokenizer_name = parsed[\"tokenizer_name\"]\n","        self.val_file = Path(parsed[\"val_file\"])\n","        self.test_file = Path(parsed[\"test_file\"])\n","        self.experiment_name = parsed[\"experiment_name\"]\n","        self.models_dir = Path(parsed[\"models_dir\"])\n","        self.checkpoint_interval = float(parsed[\"checkpoint_interval\"])\n","\n","        self.train_file = None\n","        self.train_folder = None\n","        if \"train_file\" in parsed:\n","            self.train_file = Path(parsed[\"train_file\"])\n","        elif \"train_folder\" in parsed:\n","            self.train_folder = Path(parsed[\"train_folder\"])\n","        else:\n","            raise ValueError(\n","                \"Must provide either a train_file or a train_folder in .toml file.\"\n","            )\n","\n","        self.root_model_name = None\n","        if \"root_model_name\" in parsed:\n","            self.root_model_name = parsed[\"root_model_name\"]\n","\n","        self.train_preprocessed_folder = self.get_preprocessed_folder(\"train\")\n","        self.val_preprocessed_folder = self.get_preprocessed_folder(\"validate\")\n","        self.test_preprocessed_folder = self.get_preprocessed_folder(\"test\")\n","\n","        # where will we store the checkpoints file?\n","        directory, _ = os.path.split(toml_filepath)\n","        checkpoint_csv_filename = f\"{self.experiment_name}-checkpoints.csv\"\n","        self.checkpoint_csv = Path(directory) / checkpoint_csv_filename\n","\n","    def get_preprocessed_folder(\n","        self, kind: Literal[\"train\", \"validate\", \"test\"]\n","    ) -> Path:\n","        suffix = \"-preprocessed\"\n","        if kind == \"train\":\n","            if self.train_file:\n","                name, ext = os.path.splitext(self.train_file)\n","                name += suffix\n","                assert not os.path.isfile(name)\n","                os.makedirs(name, exist_ok=True)\n","                return Path(name)\n","            elif self.train_folder:\n","                return self.train_folder.with_name(self.train_folder.name + suffix)\n","            else:\n","                raise ValueError(\n","                    \"Must provide either a train_file or a train_folder in .toml file.\"\n","                )\n","        elif kind == \"validate\":\n","            name, ext = os.path.splitext(self.val_file)\n","            name += \"-preprocessed\"\n","            assert not os.path.isfile(name)\n","            os.makedirs(name, exist_ok=True)\n","            return Path(name)\n","        elif kind == \"test\":\n","            name, ext = os.path.splitext(self.test_file)\n","            name += \"-preprocessed\"\n","            assert not os.path.isfile(name)\n","            os.makedirs(name, exist_ok=True)\n","            return Path(name)\n","        else:\n","            raise ValueError(f\"{kind} is not one of 'train', 'validate' or 'test'.\")\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hgEPwNGTgRNN"},"source":["from transformers import AutoTokenizer, PreTrainedTokenizerFast\n","\n","\n","AESW_TOKENS = [\"_MATH_\", \"_REF_\", \"_MATHDISP_\", \"_CITE_\"]\n","AESW_IDS: List[int] = []\n","BERT_IDS: Set[int] = set()\n","MAX_LEN = 256\n","\n","\n","def get_tokenizer(config: HyperParameters) -> PreTrainedTokenizerFast:\n","    tokenizer = AutoTokenizer.from_pretrained(\n","        config.tokenizer_name, do_lower_case=True, use_fast=True\n","    )\n","\n","    tokenizer.add_special_tokens({\"additional_special_tokens\": AESW_TOKENS})\n","\n","    global AESW_IDS\n","    AESW_IDS = tokenizer.convert_tokens_to_ids(AESW_TOKENS)\n","\n","    global BERT_IDS\n","    BERT_IDS = set(tokenizer.all_special_ids) - set(AESW_IDS)\n","\n","    return tokenizer\n","\n","def decode(ids: List[int], tokenizer: PreTrainedTokenizerFast) -> str:\n","    ids = list(filter(lambda i: i not in BERT_IDS, ids))\n","\n","    return cast(str, tokenizer.decode(ids, skip_special_tokens=False))\n","\n","\n","def encode_batch(\n","    sentences: List[str], tokenizer: PreTrainedTokenizerFast,\n",") -> Tuple[List[Tensor], List[Tensor]]:\n","    \"\"\"\n","    Tokenizes and pads sentences to the max length in the list of sentences. Returns tensors for input ids and tensors for attention masking.\n","    \"\"\"\n","    input_ids: List[List[int]] = []\n","\n","    for text in sentences:\n","        tokenized = tokenizer(\n","            text=text,\n","            add_special_tokens=True,\n","            max_length=MAX_LEN,  # Do truncate to MAX_LEN\n","            truncation=True,  # Do truncate\n","            padding=False,  # Don't pad\n","            return_attention_mask=False,\n","            return_token_type_ids=False,\n","        )\n","        input_ids.append(tokenized[\"input_ids\"])\n","\n","    max_len = max([len(i) for i in input_ids])\n","\n","    padded_input_ids: List[Tensor] = []\n","    attention_masks: List[Tensor] = []\n","\n","    for sent in input_ids:\n","        num_pads = max_len - len(sent)\n","\n","        padded_input_ids.append(\n","            torch.tensor(sent + [tokenizer.pad_token_id] * num_pads)  # type: ignore\n","        )\n","        attention_masks.append(torch.tensor([1] * len(sent) + [0] * num_pads))  # type: ignore\n","\n","    return padded_input_ids, attention_masks\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TzIjdfPZgRNN"},"source":["# data preparation and loading utilities\n","\n","import itertools\n","from typing import Any, Iterable, Iterator, List, Optional, Set\n","\n","import torch\n","\n","from typing import TypeVar, Union\n","\n","T = TypeVar(\"T\")\n","\n","Result = Union[T, Exception]\n","\n","\n","def is_interactive() -> bool:\n","    import __main__ as main  # type: ignore\n","\n","    return not hasattr(main, \"__file__\")\n","\n","\n","\n","def import_tqdm() -> Any:\n","    if is_interactive():\n","        return __import__(\"tqdm.notebook\").tqdm\n","    else:\n","        return __import__(\"tqdm\").tqdm\n","\n","\n","my_tqdm = import_tqdm()\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Eg9PvaCMgRNO"},"source":["import csv\n","import sys\n","from pathlib import Path\n","from typing import IO, Dict, Generic, Iterator, List, NamedTuple, Optional, Tuple\n","\n","\n","class Peekable(Generic[T]):\n","    peeked: Optional[T]\n","    it: Iterator[T]\n","\n","    def __init__(self, it: Iterator[T]):\n","        self.peeked = None\n","        self.it = it\n","\n","    def peek(self) -> Optional[T]:\n","        if not self.peeked:\n","            try:\n","                self.peeked = next(self.it)\n","            except StopIteration:\n","                return None\n","        return self.peeked\n","\n","    def pop(self) -> Optional[T]:\n","        if self.peeked:\n","            result = self.peeked\n","            self.peeked = None\n","            return result\n","        else:\n","            try:\n","                return next(self.it)\n","            except StopIteration:\n","                return None\n","\n","    def __iter__(self) -> Iterator[T]:\n","        return self.it\n","\n","class Option(NamedTuple):\n","    length: int\n","    identifier: str\n","    sentence: str\n","    label: str\n","    path: Path\n","\n","def sorted_csv_files_reader(files: List[Path]) -> Iterator[Tuple[str, int]]:\n","    opened_files: Dict[Path, IO[str]] = {}\n","    csv_readers: Dict[Path, Peekable[List[str]]] = {}\n","\n","    for filepath in files:\n","        opened_file = open(filepath, \"r\")\n","        opened_files[filepath] = opened_file\n","\n","        reader = csv.reader(opened_file)\n","        next(reader)  # skip header\n","\n","        csv_readers[filepath] = Peekable(reader)\n","\n","    while len(opened_files) > 0:\n","        best = Option(sys.maxsize, \"\", \"\", \"\", Path())\n","        finished_files = set()\n","\n","        for path, peekable in csv_readers.items():\n","            top = peekable.peek()\n","\n","            if not top:\n","                finished_files.add(path)\n","                continue  # should close the file somehow\n","\n","            identifier, sent, label = top\n","\n","            if len(sent) < best.length:\n","                best = Option(len(sent), identifier, sent, label, path)\n","\n","        # close any finished files:\n","        for path in finished_files:\n","            del csv_readers[path]\n","            opened_files[path].close()\n","            del opened_files[path]\n","\n","        # now return the best option and pop it off the iterator\n","        if best.path not in csv_readers:\n","            return\n","\n","        csv_readers[best.path].pop()\n","\n","        yield best.sentence, int(best.label)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lUpypCc4gRNO"},"source":["# function to create data files containing tokenized sentences and masks\n","\n","\n","Row = Tuple[Tensor, Tensor, Tensor]\n","\n","class RandomBatchSampler(Sampler):  # type: ignore\n","    \"\"\"\n","    Batches the data into size `batch_size`, then randomly shuffles those batches. Last batch is smaller, because there might not be a full batch.\n","    \"\"\"\n","\n","    def __init__(self, data: TensorDataset, batch_size: int):\n","        indices = list(range(len(data)))\n","        batches = [list(g) for g in grouper(indices, batch_size)]\n","\n","        *front, last = batches\n","\n","        last = [i for i in last if i]  # filter None out\n","        random.shuffle(front)\n","\n","        self.batches = front + [last]\n","\n","    def __iter__(self) -> Iterator[List[int]]:\n","        return iter(self.batches)\n","\n","    def __len__(self) -> int:\n","        return len(self.batches)\n","\n","    \n","class FileBackedSentenceDataset(TensorDataset):\n","    dirname: Path\n","    size: int\n","    files: List[str]\n","    _file_lens: List[int]\n","    _index_starts: List[int]\n","    _cached: Optional[Tuple[str, TensorDataset]]\n","\n","    def __init__(\n","        self,\n","        dirname: Path,\n","        size: int,\n","        data_files: Optional[List[Path]] = None,\n","        tokenizer: Optional[PreTrainedTokenizerFast] = None,\n","    ):\n","        \"\"\"\n","        Arguments:\n","        * dirname {str} -- the folder where the pickled TensorDatasets will be stored.\n","        * data_files {List[str]} -- the original csv file of (sentence, label) pairs. If provided, the sentences should be ordered by length from shortest to longest to make use of smart batches per https://mccormickml.com/2020/07/29/smart-batching-tutorial. If None or empty, then the dataset assumes that the pickled TensorDatasets already exist.\n","        * tokenizer {Optional[PretrainedTokenizerFast]} -- tokenizer to convert the examples in example_file\n","        \"\"\"\n","\n","        self.dirname = dirname\n","        self.size = size\n","        self.files = []\n","        self._file_lens = []\n","        self._index_starts = []\n","        self._cached = None\n","\n","        if data_files:\n","            assert tokenizer is not None, \"Need a tokenizer with an examples file\"\n","            self._save_all_datasets(data_files, tokenizer)\n","        else:\n","            self.files = [\n","                os.path.join(dirname, f)\n","                for f in sorted(os.listdir(dirname), key=lambda f: int(f[:-5]))\n","            ]\n","\n","            self._file_lens = [self.size for f in self.files]\n","            # the last file length might be short.\n","            self._file_lens[-1] = self._get_file_len(self.files[-1])\n","\n","        start = 0\n","        for file_len in self._file_lens:\n","            self._index_starts.append(start)\n","            start += file_len\n","\n","    def _save_all_datasets(\n","        self, data_files: List[Path], tokenizer: PreTrainedTokenizerFast\n","    ) -> None:\n","        \"\"\"\n","        Each datafile must be sorted by length.\n","        \"\"\"\n","        # clear any existing work\n","        shutil.rmtree(self.dirname, ignore_errors=True)\n","        os.makedirs(self.dirname, exist_ok=True)\n","\n","        sentences = []\n","        labels = []\n","        dataset_count = 0\n","\n","        for sentence, label in my_tqdm(\n","            sorted_csv_files_reader(data_files)\n","        ):\n","            sentences.append(sentence)\n","            labels.append(label)\n","\n","            if len(sentences) == self.size:\n","                self._save_dataset(\n","                    self._make_dataset(sentences, labels, tokenizer),\n","                    f\"{dataset_count}.pckl\",\n","                )\n","\n","                dataset_count += 1\n","                sentences = []\n","                labels = []\n","\n","        if sentences:\n","            self._save_dataset(\n","                self._make_dataset(sentences, labels, tokenizer),\n","                f\"{dataset_count}.pckl\",\n","            )\n","\n","    def _make_dataset(\n","        self,\n","        sentences: List[str],\n","        labels: List[int],\n","        tokenizer: PreTrainedTokenizerFast,\n","    ) -> TensorDataset:\n","        \"\"\"\n","            Arguments:\n","            * sentences {List[str]} -- The list of sentences that need to be tokenized and padded. This will always be exactly one batch.\n","            \"\"\"\n","        assert len(sentences) == len(\n","            labels\n","        ), \"Need the same number of sentences and labels\"\n","\n","        assert (\n","            len(sentences) <= self.size\n","        ), f\"{len(sentences)} must be less than {self.size}\"\n","\n","        input_ids, attention_masks = encode_batch(sentences, tokenizer)\n","\n","        input_ids_t = torch.stack(input_ids)\n","        attention_masks_t = torch.stack(attention_masks)\n","        labels_t = torch.tensor(labels)  # type: ignore\n","\n","        dataset = TensorDataset(input_ids_t, attention_masks_t, labels_t)\n","\n","        return dataset\n","\n","    def _save_dataset(self, dataset: TensorDataset, name: str) -> None:\n","        filepath = os.path.join(self.dirname, name)\n","\n","        self.files.append(filepath)\n","        self._file_lens.append(len(dataset))\n","\n","        with open(filepath, \"wb\") as file:\n","            pickle.dump(dataset, file)\n","\n","    def _find_file(self, index: int) -> int:\n","        \"\"\"\n","        Finds the i such that self._index_start[i] <= index < self._index_start[i+1]. Since the array is sorted, we use binary search to find it.\n","        \"\"\"\n","        return bisect.bisect(self._index_starts, index) - 1\n","\n","    def __getitem__(self, index: int) -> Row:\n","        file_index = self._find_file(index)\n","        filename = self.files[file_index]\n","        dataset: TensorDataset\n","\n","        if self._cached is None or filename != self._cached[0]:\n","            # this is called once per batch, so it's working as expected. It's just slow.\n","            self._set_cached_file(filename)\n","\n","        name, dataset = self._cached  # type: ignore\n","        # (OO code sucks, I know that self._cached is no longer None because we call self._set_cached_file)\n","\n","        return cast(\n","            Tuple[Tensor, Tensor, Tensor],\n","            dataset[index - self._index_starts[file_index]],\n","        )\n","\n","    def _set_cached_file(self, filename: str) -> None:\n","        with open(filename, \"rb\") as f:\n","            dataset = pickle.load(f)\n","            self._cached = (filename, dataset)\n","\n","    def __len__(self) -> int:\n","        return sum(self._file_lens)\n","\n","    def _get_file_len(self, filepath: str) -> int:\n","        with open(filepath, \"rb\") as f:\n","            contents: TensorDataset = pickle.load(f)\n","\n","        return len(contents)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5MCuWr_-gRNP"},"source":["config_bert = HyperParameters('./experiments/bert_base_aesw_32_1e6/params.toml')\n","config_scibert = HyperParameters('./experiments/scibert_32_1e6/params.toml')\n","config_robert = HyperParameters('./experiments/roberta_base_aesw_32_1e6/params.toml')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vaLeZUAigRNP"},"source":["# create tokenizer\n","tokenizer_bert = get_tokenizer(config_bert)\n","tokenizer_scibert = get_tokenizer(config_scibert)\n","tokenizer_robert = get_tokenizer(config_robert)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wy81nZ_8gRNP"},"source":["# fuction to generate train data folders\n","def prepare_train_data(\n","    config: HyperParameters, tokenizer: PreTrainedTokenizerFast\n",") -> None:\n","    if config.train_file:\n","        FileBackedSentenceDataset(\n","            config.train_preprocessed_folder,\n","            config.batch_size,\n","            [config.train_file],\n","            tokenizer,\n","        )\n","    elif config.train_folder:\n","        train_files = [config.train_folder / f for f in os.listdir(config.train_folder)]\n","        FileBackedSentenceDataset(\n","            config.train_preprocessed_folder, config.batch_size, train_files, tokenizer,\n","        )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GSN8f00FgRNQ"},"source":["# call to above function\n","prepare_train_data(config_bert, tokenizer_bert)\n","prepare_train_data(config_scibert, tokenizer_scibert)\n","prepare_train_data(config_robert, tokenizer_robert)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pitl17pigRNQ"},"source":["def prepare_val_data(\n","    config: HyperParameters, tokenizer: PreTrainedTokenizerFast\n",") -> None:\n","    FileBackedSentenceDataset(\n","        config.val_preprocessed_folder, config.batch_size, [config.val_file], tokenizer,\n","    )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7-dpYdKXgRNQ"},"source":["prepare_val_data(config_bert, tokenizer_bert)\n","prepare_val_data(config_scibert, tokenizer_scibert)\n","prepare_val_data(config_robert, tokenizer_robert)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6xuQByJKgRNQ"},"source":["def prepare_test_data(\n","    config: HyperParameters, tokenizer: PreTrainedTokenizerFast\n",") -> None:\n","    FileBackedSentenceDataset(\n","        config.test_preprocessed_folder,\n","        config.batch_size,\n","        [config.test_file],\n","        tokenizer,\n","    )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pdORzY7wgRNR"},"source":["prepare_test_data(config_bert, tokenizer_bert)\n","prepare_test_data(config_scibert, tokenizer_scibert)\n","prepare_test_data(config_robert, tokenizer_robert)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"N_4QiJ3WgRNR"},"source":["# Training and Validation"]},{"cell_type":"markdown","metadata":{"id":"nlmvH2RmgRNR"},"source":["## 2.1 Training"]},{"cell_type":"code","metadata":{"id":"gQt6yyHxgRNR"},"source":["import torch.nn.functional as F\n","from torch import Tensor, nn\n","from torch.optim import Optimizer\n","from transformers import AdamW, AutoModelForSequenceClassification, BertPreTrainedModel"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rl8zcniDgRNS"},"source":["class SentenceClassificationModel(nn.Module):\n","    def __init__(self, bert_model: BertPreTrainedModel) -> None:\n","        super().__init__()  # type: ignore\n","        self.bert = bert_model\n","\n","    def forward(self, input_ids: Tensor, attn_mask: Tensor, **kwargs: Any) -> Tensor:\n","        if \"output_attentions\" not in kwargs:\n","            kwargs[\"output_attentions\"] = False\n","\n","        logits: Tensor = self.bert(input_ids, attention_mask=attn_mask, **kwargs)[0]\n","        return logits\n","\n","    def get_optimizer(self, config: HyperParameters) -> Optimizer:\n","        return AdamW(self.parameters(), lr=config.learning_rate, eps=1e-8)  # type: ignore"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"faUKrHOUgRNS"},"source":["# train utilities\n","\n","def grouper(\n","    iterable: Iterable[T], n: int, fillvalue: Optional[T] = None\n",") -> Iterator[List[T]]:\n","    args = [iter(iterable)] * n\n","    return itertools.zip_longest(*args, fillvalue=fillvalue)\n","\n","def get_device() -> torch.device:  # type: ignore\n","    if torch.cuda.is_available():\n","        return torch.device(\"cuda\")  # type: ignore\n","    else:\n","        return torch.device(\"cpu\")  # type: ignore"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"UlPO7FBfgRNS","outputId":"091905a2-7502-472a-bef5-23547a777ce7"},"source":["bert = AutoModelForSequenceClassification.from_pretrained(config_bert.model_name)\n","print(bert.get_input_embeddings())\n","bert.resize_token_embeddings(len(tokenizer_bert))\n","print(bert.get_input_embeddings())\n","model_bert = SentenceClassificationModel(bert)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["Embedding(30522, 768, padding_idx=0)\n","Embedding(30526, 768)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_R6GPc5AgRNS","outputId":"147a51f8-7e48-40e0-d8fc-fd95e79d54bc"},"source":["scibert = AutoModelForSequenceClassification.from_pretrained(config_scibert.model_name)\n","print(scibert.get_input_embeddings())\n","scibert.resize_token_embeddings(len(tokenizer_scibert))\n","print(scibert.get_input_embeddings())\n","model_scibert = SentenceClassificationModel(scibert)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["Embedding(31090, 768, padding_idx=0)\n","Embedding(31094, 768)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BtCtBg4bgRNT","outputId":"0bb75cd7-4d6e-4e64-a7a1-5103661a7d11"},"source":["robert = AutoModelForSequenceClassification.from_pretrained(config_robert.model_name)\n","print(robert.get_input_embeddings())\n","robert.resize_token_embeddings(len(tokenizer_robert))\n","print(robert.get_input_embeddings())\n","model_robert = SentenceClassificationModel(robert)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["Embedding(50265, 768, padding_idx=1)\n","Embedding(50269, 768)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"iEn5z_DQgRNT"},"source":["def train_models(model, config, model_name, checkpoint, epoch):\n","    \"\"\"\n","     train different models\n","    \"\"\"\n","    \n","    optimizer = model.get_optimizer(config)\n","    \n","    if checkpoint!=0:\n","        disk_model = torch.load(os.path.join(config.models_dir,model_name+'_at_epoch_'+str(checkpoint-1)+'.pt'))\n","        model.load_state_dict(disk_model[\"model_state_dict\"])\n","        model.to(get_device())\n","        optimizer.load_state_dict(disk_model[\"optimizer_state_dict\"])\n","\n","    try:\n","        model.cuda()\n","    except:\n","        pass\n","    \n","    epoch = epoch #config.max_epochs\n","    seen = 0\n","    loss = 0.0\n","    \n","    small = False\n","    \n","    # creating train data loader\n","\n","    train_dataset = FileBackedSentenceDataset(\n","            config.train_preprocessed_folder, size=config.batch_size\n","        )\n","\n","    if small:\n","        train_dataset = Subset(  # type: ignore\n","            train_dataset, list(range(min(len(train_dataset), config.batch_size * 8)))\n","        )\n","\n","    train_loader = DataLoader(\n","            train_dataset,\n","            pin_memory=False,\n","            batch_sampler=RandomBatchSampler(train_dataset, config.batch_size),\n","        )\n","    \n","    model.train()\n","    \n","    for i in range(epoch):\n","        \n","        device = get_device()\n","        epoch_loss = 0\n","        for seen, batch in enumerate(my_tqdm(train_loader)):\n","\n","            input_ids = batch[0].to(device)\n","            attention_mask = batch[1].to(device)\n","            labels = batch[2].to(device)\n","\n","            model.zero_grad()\n","\n","            logits = model(input_ids, attention_mask)\n","\n","            loss = F.cross_entropy(logits.view(-1, 2), labels.view(-1))\n","\n","            loss.backward()  # type: ignore\n","\n","            optimizer.step()\n","\n","            epoch_loss += loss.detach().item()\n","        \n","        \n","    \n","        avg_loss = epoch_loss / len(train_loader)    \n","        print(f\"Training loss: {avg_loss:.3f}\")\n","        \n","        disk_model = {\n","            \"epoch\": epoch,\n","            \"model_state_dict\": model.state_dict(),\n","            \"optimizer_state_dict\": optimizer.state_dict(),\n","            \"epoch loss\": epoch_loss,\n","            \"avg loss\": avg_loss\n","        }\n","    \n","        torch.save(disk_model, os.path.join(config.models_dir, model_name+'_at_epoch_'+str(checkpoint+i)+'.pt'))\n","        \n","    disk_model = {\n","        \"model_state_dict\": model.state_dict(),\n","        \"optimizer_state_dict\": optimizer.state_dict(),\n","        }\n","\n","    torch.save(disk_model, os.path.join(config.models_dir, 'final'+model_name+'.pt'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"80aHxlWXgRNU"},"source":["train_models(model_bert, config_bert, 'bert', 0, 1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TCQ77r7DgRNU"},"source":["train_models(model_scibert, config_scibert, 'scibert.pt', 0, 1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"f84u8kEjgRNU"},"source":["train_models(model_robert, config_robert, 'robert.pt', 0, 1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"l7iYTU56gRNU"},"source":["## 2.2 Validation"]},{"cell_type":"code","metadata":{"id":"hu_40eGfgRNV"},"source":["disk_model = torch.load(os.path.join(config_bert.models_dir,'bert_at_epoch_0.pt'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"y6y-ZjESgRNV"},"source":["# create blank  BERT model\n","bert = AutoModelForSequenceClassification.from_pretrained(config_bert.model_name)\n","bert.resize_token_embeddings(len(tokenizer_bert))\n","model_bert = SentenceClassificationModel(bert)\n","# create blank optimizer\n","optimizer_bert = model_bert.get_optimizer(config_bert)\n","\n","# load model state\n","model_bert.load_state_dict(disk_model[\"model_state_dict\"])\n","model_bert.to(get_device())\n","\n","# load optimizer state\n","optimizer.load_state_dict(disk_model[\"optimizer_state_dict\"])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b51rVywSgRNV"},"source":["# creating validation data loader\n","\n","val_dataset = FileBackedSentenceDataset(\n","        config.val_preprocessed_folder, size=config.batch_size\n","    )\n","\n","if small:\n","    val_dataset = Subset(val_dataset, list(range(config.batch_size * 8)))\n","\n","val_dataloader = DataLoader(\n","    val_dataset, shuffle=False, pin_memory=True, batch_size=config.batch_size\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AziaDTzogRNV"},"source":["@dataclass\n","class ConfusionMatrix:\n","    TP: int\n","    TN: int\n","    FP: int\n","    FN: int\n","\n","    def __add__(self, other: \"ConfusionMatrix\") -> \"ConfusionMatrix\":\n","        return ConfusionMatrix(\n","            self.TP + other.TP,\n","            self.TN + other.TN,\n","            self.FP + other.FP,\n","            self.FN + other.FN,\n","        )\n","\n","    @property\n","    def accuracy(self) -> float:\n","        return (self.TP + self.TN) / self.total\n","\n","    @property\n","    def f1(self) -> float:\n","        denominator = self.precision + self.recall\n","\n","        if denominator == 0:\n","            print(\"Both precision and recall were 0; not going to divide by 0.\")\n","            return 0\n","\n","        return (2 * self.precision * self.recall) / (self.precision + self.recall)\n","\n","    @property\n","    def recall(self) -> float:\n","        if self.TP + self.FN == 0:\n","            # means there are no negative examples (unlikely)\n","            print(\"No negative examples provided; not going to divide by 0.\")\n","            return 1\n","        return self.TP / (self.TP + self.FN)\n","\n","    @property\n","    def precision(self) -> float:\n","        if self.TP + self.FP == 0:\n","            # means we didn't guess positive for any examples\n","            return 0\n","        return self.TP / (self.TP + self.FP)\n","\n","    @property\n","    def total(self) -> int:\n","        return self.TP + self.FP + self.TN + self.FN"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"m9RPCg5ogRNW"},"source":["def get_confusion_matrix(logits: Tensor, labels: Tensor) -> ConfusionMatrix:\n","    _, predicted = torch.max(logits.data, 1)  # type: ignore\n","\n","    true_pos: int = ((predicted * labels) != 0).sum().item()\n","    true_neg: int = (((predicted - 1) * (labels - 1)) != 0).sum().item()\n","    false_pos: int = ((predicted * (labels - 1)) != 0).sum().item()\n","    false_neg: int = (((predicted - 1) * labels) != 0).sum().item()\n","\n","    confusion = ConfusionMatrix(true_pos, true_neg, false_pos, false_neg)\n","\n","    assert confusion.total == len(\n","        predicted\n","    ), f\"confusion matrix {confusion} doesn't have the same number of results as {labels}: {confusion.total} != {len(labels)}\"\n","\n","    return confusion"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b7HjIRR-gRNW","outputId":"1c7aff88-b507-447a-8cba-ee8cc0ff5b5c"},"source":["total_loss = 0\n","total_confusion = ConfusionMatrix(0,0,0,0)\n","\n","for batch in my_tqdm(val_dataloader):\n","    input_ids = batch[0].to(device)\n","    attention_mask = batch[1].to(device)\n","    labels = batch[2].to(device)\n","\n","    with torch.no_grad():\n","        logits = model(input_ids, attention_mask)\n","\n","    loss = F.cross_entropy(logits.view(-1, 2), labels.view(-1))\n","\n","    total_loss += loss.detach().item()\n","    total_confusion = total_confusion + get_confusion_matrix(\n","        logits, labels\n","    )\n","\n","avg_loss = total_loss / len(val_dataloader)\n","\n","print(\n","    f\"\"\"Validation loss: {avg_loss:.3f}\n","Validation accuracy: {total_confusion.accuracy:.3f}\n","Validation F1: {total_confusion.f1:.3f}\n","Validation precision: {total_confusion.precision:.3f}\n","Validation recall: {total_confusion.recall:.3f}\"\"\"\n",")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["100%|██████████| 4608/4608 [52:45<00:00,  1.46it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation loss: 0.523\n","Validation accuracy: 0.737\n","Validation F1: 0.613\n","Validation precision: 0.717\n","Validation recall: 0.535\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"p7TrAO__gRNW"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GyCRCyjRgRNW"},"source":["# 3. Interpretability"]},{"cell_type":"markdown","metadata":{"id":"5DDtydO4gRNX"},"source":["## 3.1 Edits "]},{"cell_type":"markdown","metadata":{"id":"F6l8TjcmgRNX"},"source":["### There are two type of edits in a sentence \"Spell correction edits\" and \"Word deletion edits\".\n","\n","\n","\n","<p> For each sentence we store a tuple containing following information related to edit operation: \n","    \n","    1. sentence id\n","    2. raw sentence (unedited)\n","    3. tokenized (nltk tokenizer) words from the sentence\n","    4. index of the word which needs edit\n","    \n","    Following is the format of storing edits .\n","    \n","        (\n","        < sentence id > ,\n","        < raw sentence (unedited) >,\n","        < tokenized (nltk tokenizer) words from the sentence >, \n","        < index of the word which needs edit >\n","        )\n","    \n","    example:\n","    \n","    Case 1) For sentence containing spell correction edit\n","            Edit: <sen> I came <del>hame</del><ins>home</ins> early </sen> \n","            Storage format : (101. ,\"I came hame early\" , [[CLS], \"I\", \"came\", \"hame\", \"early\", [SEP]], [3])\n","      \n","    Case 2) For sentence containing word deletion edit\n","            Edit: <sen> I <del>was</del> came home home early </sen> \n","            Storage format : (102. ,\"I was came home early\" ,[[CLS],\"I\",\"was\",\"came\",\"home\",\"early\", [SEP]], [2]) \n","            \n","    The tuples are stored in a list. List is stored in a pickle\n","<p>\n","            \n","### We maintain separate picke file for each type of edit namely \"spelling.pckl\" and \"deleted.pckl\".\n","    \n","![title](https://i.ibb.co/C5Cm9bS/Screenshot-2021-06-14-at-2-50-39-PM.png)"]},{"cell_type":"code","metadata":{"id":"0Q8i6VgXgRNX"},"source":["# utilities\n","from typing import Iterable, List, TypeVar, NamedTuple\n","\n","import nltk\n","\n","T = TypeVar(\"T\")\n","\n","def tokenize_transformer_sentences(\n","    sent: str, add_special_tokens: bool = True\n",") -> List[str]:\n","    if add_special_tokens:\n","        sent = \"[CLS] \" + sent + \" [SEP]\"\n","\n","    raw_tokens = nltk.word_tokenize(sent)\n","\n","    def fix_quotes(token: str) -> str:\n","        if token == \"``\":\n","            return '\"'\n","        if token == \"''\":\n","            return '\"'\n","        return token\n","\n","    raw_tokens = [fix_quotes(token) for token in raw_tokens]\n","\n","    arbitrary_token = \"\\t\"\n","\n","    return (\n","        arbitrary_token.join(raw_tokens)\n","        .replace(f\"[{arbitrary_token}CLS{arbitrary_token}]\", \"[CLS]\")\n","        .replace(f\"[{arbitrary_token}SEP{arbitrary_token}]\", \"[SEP]\")\n","        .split()\n","    )\n","\n","def chunks(elements: Iterator[T], n: int) -> Iterator[List[T]]:\n","    \"\"\"\n","    Yield successive n-sized chunks from elements.\n","    \"\"\"\n","\n","    while True:\n","        chunk = []\n","        for i in range(n):\n","            try:\n","                chunk.append(next(elements))\n","            except StopIteration:\n","                yield chunk\n","                return\n","\n","        yield chunk\n","\n","def get(s: Set[T]) -> T:\n","    return next(iter(s))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KXXq7nhfgRNX"},"source":["def get_deleted_word_indices(sent_elem: etree._Element) -> Tuple[List[str], Set[int]]:\n","    assert sent_elem.tag == \"sentence\"\n","\n","    sent_text, mask = extract_sentence_with_mask(sent_elem)\n","    words = tokenize_transformer_sentences(sent_text, add_special_tokens=False)\n","\n","    if not any([elem.tag == \"del\" for elem in sent_elem]):\n","        return words, set()\n","\n","    word_i = 0\n","    word_ch_i = 0\n","    sent_i = 0\n","\n","    best_words = set()\n","\n","    while word_i < len(words) and sent_i < len(sent_text):\n","        if mask[sent_i] != \" \":\n","            best_words.add(word_i)\n","        word_ch_i += 1\n","        sent_i += 1\n","\n","        if word_ch_i >= len(words[word_i]):\n","            word_i += 1\n","            word_ch_i = 0\n","            # skip whitespace in sent\n","            while sent_i < len(sent_text) and sent_text[sent_i] in string.whitespace:\n","                sent_i += 1\n","\n","        if sent_i >= len(sent_text):\n","            break\n","\n","        assert (\n","            words[word_i][word_ch_i] == sent_text[sent_i]\n","        ), f\"'{words[word_i][word_ch_i]}' != '{sent_text[sent_i]}' ({extract_sentence_id(sent_elem)})\"\n","\n","    words.insert(0, \"[CLS]\")\n","    words.append(\"[SEP]\")\n","    best_words = set([b + 1 for b in best_words])  # all incremented because of [CLS]\n","\n","    return words, best_words\n","\n","\n","def extract_sentence_with_mask(sent_elem: etree._Element) -> Tuple[str, str]:\n","    assert sent_elem.tag == \"sentence\"\n","    string_builder = [str(sent_elem.text) if sent_elem.text else \"\"]\n","    mask_builder = [\" \" * len(str(sent_elem.text)) if sent_elem.text else \"\"]\n","\n","    for del_ins in sent_elem:\n","        if del_ins.tag == \"del\" and del_ins.text:\n","            string_builder.append(str(del_ins.text))\n","            mask_builder.append(\"*\" * len(string_builder[-1]))\n","        if del_ins.tail:\n","            string_builder.append(str(del_ins.tail))\n","            mask_builder.append(\" \" * len(string_builder[-1]))\n","\n","    assert len(mask_builder) == len(string_builder)\n","\n","    sent = \"\".join(string_builder)\n","    mask = \"\".join(mask_builder)\n","\n","    assert len(sent) == len(mask)\n","\n","    return sent, mask"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9sNJBZrOgRNX"},"source":["import string\n","from spellchecker import SpellChecker\n","\n","spell = SpellChecker()\n","\n","# file paths\n","DEV_XML = \"./data-unversioned/aesw/aesw2016(v1.2)_dev.xml\"\n","\n","INTERPRETABILITY_FOLDER = Path(\"./data-unversioned/attention-weights/\")\n","\n","class Edit(NamedTuple):\n","    id: str\n","    sent: str\n","    words: List[str]\n","    best_words: Set[int]\n","        \n","def save_edits(edits: List[Edit], filename: str) -> None:\n","    '''\n","        method for saving edits\n","    '''\n","    with open(INTERPRETABILITY_FOLDER / filename, \"wb\") as file:\n","        pickle.dump(edits, file)\n","        \n","def load_edits(filename: str) -> List[Edit]:\n","    \"\"\"\n","        method for loading edits\n","    \"\"\"\n","    with open(INTERPRETABILITY_FOLDER / filename, \"rb\") as file:\n","        return pickle.load(file)  # type: ignore\n","\n","def is_only_deleted(sent_elem: etree._Element) -> bool:\n","    \"\"\"\n","        returns True if edit in sentence is of type word deletion\n","    \"\"\"\n","    assert sent_elem.tag == \"sentence\"\n","\n","    if len(sent_elem) == 0:\n","        return False\n","\n","    for edit_elem in sent_elem:\n","        if edit_elem.tag != \"del\":\n","            return False\n","\n","    return True\n","\n","def is_only_spelling_error(sent_elem: etree._Element) -> bool:\n","    \"\"\"\n","        returns True if edit in sentence is of type word correction\n","    \"\"\"\n","    assert sent_elem.tag == \"sentence\"\n","\n","    if len(sent_elem) != 2:  # should be one delete, one insert\n","        return False\n","\n","    del_elem, ins_elem = list(sent_elem)\n","\n","    if (\n","        del_elem.tail\n","    ):  # should be no text between the deleted text and the inserted text\n","        return False\n","\n","    if del_elem.tag != \"del\" or ins_elem.tag != \"ins\":\n","        return False\n","\n","    misspelled_words = spell.unknown([del_elem.text])\n","\n","    if not misspelled_words:\n","        return False\n","\n","    misspelled_word = get(misspelled_words)\n","\n","    if misspelled_word in string.whitespace or \" \" in misspelled_word:\n","        return False\n","\n","    corrections = spell.unknown([ins_elem.text])\n","\n","    if (\n","        len(corrections) > 0\n","    ):  # still misspelled, but not always correct. Might want to use edit distance\n","        return False\n","\n","    return True\n","\n","def get_edits_with_only_deleted_words(again: bool = False) -> List[Edit]:\n","    '''\n","        \n","        Stores sentences having spelling errors in a separate file in following format.\n","        \n","        [sent_id, sent, words, best_words]\n","        \n","        sent_id: unique id of a sentence edit record in DEV file\n","        sent: actual sentence without any tags\n","        words: tokenized sentence (nltk tokenizer used)\n","        best_word: list of indices of tokens in \"words\" array needing manipulation \n","        \n","        eg: [1, \"I was came home early\", [\"[CLS]\", \"I\", \"was\",\"came\", \"home\", \"[SEP]\"], [2]]\n","        \n","    '''\n","        \n","    filename = \"deleted.pckl\"\n","    try:\n","        if not again:\n","            return load_edits(filename)\n","    except FileNotFoundError:\n","        pass\n","\n","    results = []\n","\n","    for _, sent_elem in my_tqdm(\n","        etree.iterparse(DEV_XML, tag=\"sentence\")\n","    ):\n","        sent_id = extract_sentence_id(sent_elem)\n","        sent = extract_sentence(sent_elem)\n","        \n","        # check if the sentence has edit of type word deletion\n","        if not is_only_deleted(sent_elem):\n","            continue\n","        \n","        # get tokenized (nltk) sentence and indices of words needing deletion\n","        words, best_words = get_deleted_word_indices(sent_elem)\n","        \n","        # prepare a tuple\n","        edit = Edit(sent_id, sent, words, best_words)\n","        \n","        # store in array\n","        results.append(edit)\n","\n","    save_edits(results, filename)\n","\n","    return results\n","\n","def get_edits_with_only_spelling_errors(again: bool = False) -> List[Edit]:\n","    '''\n","        \n","        Stores sentences having spelling errors in a separate file in following format.\n","        \n","        [sent_id, sent, words, best_words]\n","        \n","        sent_id: unique id of a sentence edit record in DEV file\n","        sent: actual sentence without any tags\n","        words: tokenized sentence (nltk tokenizer used)\n","        best_word: list of indices of tokens in \"words\" array needing manipulation \n","        \n","        eg: [1, \"I came hame early\", [\"[CLS]\", \"I\", \"came\", \"hame\", \"[SEP]\"], [3]]\n","        \n","    '''\n","    \n","    filename = \"spelling.pckl\" \n","    try:\n","        if not again:\n","            return load_edits(filename)\n","    except FileNotFoundError:\n","        pass\n","\n","    results = []\n","\n","    for _, sent_elem in my_tqdm(\n","        etree.iterparse(DEV_XML, tag=\"sentence\")\n","    ):\n","        sent_id = extract_sentence_id(sent_elem)\n","        sent = extract_sentence(sent_elem)\n","        \n","        # check if the sentence has edit of type spell correction\n","        if not is_only_spelling_error(sent_elem):\n","            continue\n","        \n","        # get tokenized (nltk) sentence and indices of words needing correction\n","        words, best_words = get_deleted_word_indices(sent_elem)\n","        \n","        # prepare a tuple\n","        edit = Edit(sent_id, sent, words, best_words)\n","        \n","        # store in array\n","        results.append(edit)\n","\n","    save_edits(results, filename)\n","\n","    return results"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wsWOoUoegRNY"},"source":["# get sentences conatining word deletion change and store in a separate file\n","deleted_edits = get_edits_with_only_deleted_words()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Excr1A8OgRNY","outputId":"22179731-09d7-4bf7-b293-d16730fab4a9"},"source":["# get sentences conatining word spell check change and store in a separate file\n","spell_edits = get_edits_with_only_spelling_errors(again=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["147446it [00:01, 80650.26it/s]\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"a1dgKB34gRNY"},"source":["## 3.2 Edit weights"]},{"cell_type":"markdown","metadata":{"id":"KaWf8yPcgRNZ"},"source":["### Once the pickle files of respective edits have been made.\n","\n","### We start storing model specific attention weights of last layer for each sentence to be predicted.\n","\n","<p><b>For each model: </b><br>\n","   &emsp;&emsp;<b> For each edit type: </b><br>\n","   &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;Following is the process which we carry out for each and every sentence to be predicted.\n","</p>\n","    \n","\n","![title](https://i.ibb.co/myy70Db/Screenshot-2021-06-14-at-4-41-02-PM.png)\n","\n","\n","### Output of the above process is stored in pickle file as shown below. \n","#### We will have in total  4 ( No. of models ) x 2 ( No. of edit types ) = 8 pickle files \n","\n","\n","\n","![title](https://i.ibb.co/WNrWrgp/Screenshot-2021-06-14-at-4-40-41-PM.png)\n","\n","\n","### Importance of merge attention process.\n","\n","<p> While prediction we tokenize the input sentences with model specific tokenizer which may produce tokenized words as shown in following example.\n","    <br> <b>Input sentence :</b> <b>[ I came hame early ]</b>\n","    <br> <b> Tokenized sentence :</b>\n","    <br>\n","</p>\n","\n","![title](https://i.ibb.co/mD6HZks/Screenshot-2021-06-14-at-4-53-55-PM.png)\n","\n","<p> But for analysis purpose we would require tokenized sentence in following format </p>\n","\n","![title](https://i.ibb.co/tpnP3Cj/Screenshot-2021-06-14-at-4-54-05-PM.png)\n","\n","\n","<p>Following image describes the merge attention process:\n","    <br>\n","    Merge attention process transforms the attention matrix as shown below : \n","</p>\n","\n","\n","![title](https://i.ibb.co/P5B1M4V/Screenshot-2021-06-14-at-4-53-44-PM.png)\n","\n","<p> The obtained attention matrix is used further for analysis. </p>\n"]},{"cell_type":"code","metadata":{"id":"r6cYFTrNgRNZ"},"source":["from transformers import (\n","    BertForSequenceClassification,\n","    BertTokenizerFast,\n","    PreTrainedModel,\n","    PreTrainedTokenizerFast,\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"64Vsyw_ZgRNZ"},"source":["Model = Tuple[\n","    SentenceClassificationModel, PreTrainedModel, PreTrainedTokenizerFast\n","]\n","\n","def load_finetuned_model_from_disk(\n","    config: HyperParameters, filepath: Path\n",") -> Result[Tuple[SentenceClassificationModel, torch.optim.Optimizer]]:\n","    disk_model: DiskModel\n","\n","    try:\n","        if torch.cuda.is_available():\n","            disk_model = torch.load(filepath)  # type: ignore\n","        else:\n","            disk_model = torch.load(filepath, map_location=torch.device(\"cpu\"))  # type: ignore\n","    except Exception as err:\n","        return err\n","    \n","    bert = AutoModelForSequenceClassification.from_pretrained(config.model_name)\n","\n","    bert.resize_token_embeddings(len(get_tokenizer(config)))\n","\n","    model = SentenceClassificationModel(bert)\n","    optimizer = model.get_optimizer(config)\n","\n","    model.load_state_dict(disk_model[\"model_state_dict\"])\n","    model.to(get_device())\n","\n","    optimizer.load_state_dict(disk_model[\"optimizer_state_dict\"])\n","\n","    return model, optimizer\n","\n","def load_bert_default() -> Model:\n","    \"\"\"\n","        load default bert model\n","    \"\"\"\n","    default_model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\")\n","\n","    if torch.cuda.is_available():\n","        default_model.cuda()\n","\n","    cls_model = SentenceClassificationModel(default_model)\n","\n","    bert_tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")\n","\n","    return cls_model, default_model.bert, bert_tokenizer\n","\n","def load_bert() -> Model:\n","    \"\"\"\n","        load finetuned bert model\n","    \"\"\"\n","    bert_config = HyperParameters(\n","        \"./experiments/bert_base_aesw_32_1e6/params.toml\"\n","    )\n","    disk_model = load_finetuned_model_from_disk(\n","        bert_config, Path(\"./models/bert_at_epoch_0.pt\"),\n","    )\n","    if isinstance(disk_model, Exception):\n","        raise disk_model\n","\n","    bert, _ = disk_model\n","    bert_tokenizer = get_tokenizer(bert_config)\n","    return bert, bert.bert.bert, bert_tokenizer\n","\n","def load_scibert() -> Model:\n","    \"\"\"\n","        load finetuned scibert model\n","    \"\"\"\n","    scibert_config = HyperParameters(\n","        \"./experiments/scibert_32_1e6/params.toml\"\n","    )\n","    disk_model = load_finetuned_model_from_disk(\n","        scibert_config,\n","        Path(\"./models/scibert_at_epoch_0.pt\"),\n","    )\n","    if isinstance(disk_model, Exception):\n","        raise disk_model\n","\n","    scibert, _ = disk_model\n","    scibert_tokenizer = get_tokenizer(scibert_config)\n","    return scibert, scibert.bert.bert, scibert_tokenizer\n","\n","\n","def load_roberta() -> Model:\n","    \"\"\"\n","        load finetuned roberta model\n","    \"\"\"\n","    roberta_config = HyperParameters(\n","        \"./experiments/roberta_base_aesw_32_1e6/params.toml\"\n","    )\n","    disk_model = load_finetuned_model_from_disk(\n","        roberta_config,\n","        Path(\"./models/robert_at_epoch_0.pt\"),\n","    )\n","    if isinstance(disk_model, Exception):\n","        raise disk_model\n","\n","    roberta, _ = disk_model\n","    roberta_tokenizer = get_tokenizer(roberta_config)\n","    return roberta, roberta.bert.roberta, roberta_tokenizer\n","\n","def get_all_models(finetuned_only: bool = False) -> Dict[str, Model]:\n","    \"\"\"\n","        load all models\n","    \"\"\"\n","    if finetuned_only:\n","        return {\n","            \"bert\": load_bert(),\n","            \"scibert\": load_scibert(),\n","            \"roberta\": load_roberta(),\n","        }\n","    else:\n","        return {\n","            \"bert\": load_bert(),\n","            \"scibert\": load_scibert(),\n","            \"roberta\": load_roberta(),\n","#             \"bert_glue\": load_bert_glue(),\n","            \"bert_default\": load_bert_default(),\n","        }"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AV3eRiRIgRNa"},"source":["class ModelOutput(NamedTuple):\n","    words: List[str]\n","    attention: np.ndarray\n","    prediction: bool\n","\n","Cache = Dict[str, Tuple[List[str], np.ndarray, bool]]\n","\n","def get_word_ends_from_tokens(tokens: List[str], words: List[str]) -> List[str]:\n","    assert tokens[0] == words[0], f\"{tokens[0]} != {words[0]}\"\n","    assert tokens[-1] == words[-1]\n","\n","    word_ends = []\n","\n","    word_i = 0\n","    token_i = 0\n","    while word_i < len(words) and token_i < len(tokens):\n","        if words[word_i].lower().endswith(tokens[token_i].lower().strip()):\n","            word_ends.append(tokens[token_i])\n","            word_i += 1\n","\n","        token_i += 1\n","\n","    return word_ends\n","\n","\n","def format_special_chars(tokens: List[str]) -> List[str]:\n","    return [\n","        t.replace(\"Ġ\", \" \").replace(\"▁\", \" \").replace(\"</w>\", \"\").replace(\"##\", \"\")\n","        for t in tokens\n","    ]\n","\n","def merge_attention_head(\n","    attention_head: np.ndarray,\n","    tokens: List[str],\n","    words: List[str],\n","    word_ends: List[str],\n","    verbose: int = 0,\n",") -> np.ndarray:\n","    \n","    \n","    \"\"\"\n","        returns attention block of shape 12 x len(words) x len(words)\n","        where , words = words array obtained after tokenization of sentence with nltk tokenizer\n","    \"\"\"\n","    assert attention_head.shape == (len(tokens), len(tokens)), str(attention_head.shape)\n","\n","    if verbose == 1:\n","        print(attention_head.shape)\n","        print()\n","    if verbose == 2:\n","        print(attention_head)\n","        print()\n","\n","    # step 1: merge attention *to* split words\n","\n","    merged_attention = np.zeros((len(tokens), len(words)))\n","\n","    for token_i, token_from in enumerate(tokens):\n","        attention_sum = 0\n","        word_j = -1\n","        for token_j, token_to in enumerate(tokens):\n","            attention_sum += attention_head[token_i, token_j]\n","            if token_to in word_ends[word_j + 1 :]:\n","                word_j = word_ends.index(token_to, word_j + 1)\n","                merged_attention[token_i, word_j] = attention_sum\n","                attention_sum = 0\n","\n","    if verbose == 1:\n","        print(merged_attention.shape)\n","        print()\n","    if verbose == 2:\n","        print(merged_attention)\n","        print()\n","\n","    final_attention = np.zeros((len(words), len(words)))\n","\n","    # step 2: merge attention *from* split words\n","\n","    for word_j, word in enumerate(words):\n","        word_i = -1\n","        attention_to_word = 0\n","        tokens_to_word_count = 0\n","        for token_i, token in enumerate(tokens):\n","            attention_to_word += merged_attention[token_i, word_j]\n","            tokens_to_word_count += 1\n","\n","            if token in word_ends[word_i + 1 :]:\n","                word_i = word_ends.index(token, word_i + 1)\n","                attention_from_word = attention_to_word / tokens_to_word_count\n","                final_attention[word_i, word_j] = attention_from_word\n","                attention_to_word = 0\n","                tokens_to_word_count = 0\n","\n","    if verbose == 1:\n","        print(final_attention.shape)\n","        print()\n","    if verbose == 2:\n","        print(final_attention)\n","        print()\n","\n","    return final_attention\n","\n","def get_words_and_attention_and_prediction(\n","    sents: List[str],\n","    cls_model: SentenceClassificationModel,\n","    model: PreTrainedModel,\n","    tokenizer: PreTrainedTokenizerFast,\n",") -> List[ModelOutput]:\n","    \"\"\"\n","     returns words, merged attentions, predictions for a particular sentence edit\n","    \"\"\"\n","    if not sents:\n","        return []\n","    \n","    # tokenize(nltk) each and every sentence in a batch\n","    words = [tokenize_transformer_sentences(sent) for sent in sents]\n","    \n","    # tokenize the sentence with model specific tokenizers to send the tokenized word array for prediction\n","    inputs = tokenizer.batch_encode_plus(\n","        sents, return_tensors=\"pt\", add_special_tokens=True, padding=True\n","    )\n","\n","    device = get_device()\n","    \n","    # extract tokenized words\n","    input_ids = inputs[\"input_ids\"].to(device)\n","    # extract mask of determining tokenied words + padding\n","    attn_mask = inputs[\"attention_mask\"].to(device)\n","    \n","    # perform batch prediction\n","    with torch.no_grad():\n","        attention = model(input_ids, output_attentions=True)[-1]\n","\n","        logits = cls_model(input_ids, attn_mask=attn_mask)\n","        _, raw_predictions = torch.max(logits.data, 1)  # type: ignore\n","\n","        predictions: List[int] = raw_predictions.tolist()\n","\n","    # attention is a tuple of length 12\n","    # each element in attention is a tensor len(sents) x 12 x max_seq_len x max_seq_len\n","\n","    results = []\n","\n","    for i in range(len(sents)):\n","        # get tokens\n","        input_id_list = input_ids[i].tolist()\n","        tokens: List[str] = tokenizer.convert_ids_to_tokens(input_id_list)\n","\n","        tokens[0] = \"[CLS]\"\n","\n","        # last token isn't always [SEP] so we normalize\n","        last_token = tokens.index(tokenizer.sep_token)\n","        tokens[last_token] = \"[SEP]\"\n","\n","        # only care about non-padding tokens\n","        tokens = tokens[: last_token + 1]\n","        tokens = format_special_chars(tokens)\n","        \n","        # getting word ends of each nltk-tokenized word from words tokenized with model tokenizer \n","        word_ends = get_word_ends_from_tokens(tokens, words[i])\n","\n","        # get attention and remove the values that should be masked\n","        word_attention = []\n","        \n","        # call merge attention for attention block of each of the 12 attention heads\n","        for attention_head in attention[11][i]:\n","            relevant_attn = attention_head.numpy()[: last_token + 1, : last_token + 1]\n","            word_attn = merge_attention_head(relevant_attn, tokens, words[i], word_ends)\n","            word_attention.append(word_attn)\n","\n","        word_attention_arr: np.ndarray = np.stack(word_attention, axis=0)\n","\n","        results.append(ModelOutput(words[i], word_attention_arr, bool(predictions[i])))\n","\n","    return results\n","\n","\n","def get_attention_weights(\n","    edits: Iterable[Edit],\n","    cls_model: SentenceClassificationModel,\n","    model: PreTrainedModel,\n","    tokenizer: PreTrainedTokenizerFast,\n","    skip_false_predictions: bool = False,\n",") -> Cache:\n","    \"\"\"\n","       returns saved list containing tuples of format (words, attn, prediction) \n","       where \n","           words: tokenized(nltk) words from sentence.\n","           attn: attention of CLS bit of last level.\n","           prediction: output of prediction 0 or 1.\n","    \"\"\"\n","    saved = {}\n","\n","    for edit_batch in my_tqdm(chunks(iter(edits), 8)):\n","        sents = [edit.sent for edit in edit_batch]\n","        \n","        # get tokenized(nltk) words , attention weights, prediction(0 or 1)\n","        result = get_words_and_attention_and_prediction(\n","            sents, cls_model, model, tokenizer\n","        )\n","\n","        for edit, (words, attn, prediction) in zip(edit_batch, result):\n","            if skip_false_predictions and not prediction:\n","                continue\n","\n","            if edit.words != words:\n","#                 print(edit.id)\n","#                 print(edit.words)\n","#                 print(words)\n","                continue\n","\n","            saved[edit.id] = (words, attn, prediction)\n","\n","    return saved\n","\n","\n","PICKLE_FOLDER = Path(\"./data-unversioned/attention-weights/\")\n","\n","def save_model_cache(model_name: str, filename: str, cache: Cache) -> None:\n","    \"\"\"\n","        method for saving model weights\n","    \"\"\"   \n","    with open(PICKLE_FOLDER / model_name / filename, \"wb\") as file:\n","        pickle.dump(cache, file)\n","        \n","def load_model_cache(model_name: str, filename: str) -> Cache:\n","    \"\"\"\n","        method for loading model weights\n","    \"\"\"\n","    with open(PICKLE_FOLDER / model_name / filename, \"rb\") as file:\n","        return pickle.load(file)  # type: ignore\n","    \n","def save_edit_weights(all_edits: Iterable[Edit], filename: str) -> None:\n","    \"\"\"\n","        predict from one model at a time and save attention weights after prediction.\n","    \"\"\"\n","    all_models = get_all_models()\n","    \n","    # save all the weights\n","    for model_name, (cls_model, model, tokenizer) in all_models.items():\n","        cache = get_attention_weights(all_edits, cls_model, model, tokenizer)\n","        save_model_cache(model_name, filename, cache)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8ukYGqs3gRNa","outputId":"db358e62-fdc8-45e1-8663-b67a2c086f29"},"source":["# extract attention weights of last layer's CLS head of BERT model, on prediction over sentences needing word \n","# deletion edit. \n","DELETE_EDIT_WEIGHTS_FILENAME = \"deleted.pckl\"\n","save_edit_weights(deleted_edits, DELETE_EDIT_WEIGHTS_FILENAME)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","843it [14:49,  1.06s/it]\n","843it [14:17,  1.02s/it]\n","843it [15:35,  1.11s/it]\n","843it [15:36,  1.11s/it]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"ctjI-fe1gRNb"},"source":["# extract attention weights of last layer's CLS head of BERT model, on prediction over sentences needing spell \n","# correction edit. \n","\n","SPELLING_EDIT_WEIGHTS_FILENAME = \"spelling.pckl\"\n","save_edit_weights(spell_edits, SPELLING_EDIT_WEIGHTS_FILENAME)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dphU7DJpgRNb"},"source":["## 3.3 Evaluation of scores"]},{"cell_type":"markdown","metadata":{"id":"qyI_V98CiAMJ"},"source":["The steps involved in evaluation process are as follows:\n","\n","<p> For each model: <br>\n","&emsp;For each sentence: <br>\n","&emsp;&emsp;We do following procedure.\n","</p>\n","\n","![title](https://i.ibb.co/Y0BK0nt/Screenshot-2021-06-14-at-7-23-41-PM.png)\n","\n","<p>\n","After completing above procedure we compute following. <br>\n","\n","For each model:<br>\n","&emsp;&emsp;For each strategy:<br>\n","&emsp;&emsp;&emsp;&emsp;&emsp;1. exact_match_accuracy <br>\n","&emsp;&emsp;&emsp;&emsp;&emsp;2. jaccard_match_accuracy <br>\n","&emsp;&emsp;&emsp;&emsp;&emsp;3. mean_jaccard_similarity <br>\n","&emsp;&emsp;&emsp;&emsp;&emsp;4. top_3_match_accuracy <br>\n","</p>\n","\n","\n","<p> Metrics Formulation: </p>\n","\n","Lets consider prediction for sentence <b>\"I came hame early\"</b>. <br>\n","In the above sentence \"hame\" word is spelled incorrectly so it should be targeted by BERT during prediction.\n","<br>\n","Let, target = ['hame']\n","<br>\n","Lets assume BERT attended following array of words in decreasing order of attention.<br>\n","Let, attended_words = ['hame', 'early', 'came', 'I']\n","\n","<b>exact_match</b>  = During a prediction, if BERT paid attention to all the actual targets or spelling mistake words in prediction then we increment this variable.<br>\n","\n","&emsp;&emsp;&emsp;&emsp;&emsp;So in our example all the targets words were attended by BERT i-e, <br>\n","\n","&emsp;&emsp;&emsp;&emsp;&emsp; target == attended_words[:len(target)] <br>\n","&emsp;&emsp;&emsp;&emsp;&emsp; i-e {'hame'}=={'hame'} <br>\n","&emsp;&emsp;&emsp;&emsp;&emsp;So we increment, exact_match.<br>\n","<br>\n","<b>exact_match_accuracy</b> = exact_match / num_predictions\n","<br>\n","\n","<b>top_3_match</b> = During a prediction, if target words set is found to be subset of top 3 attended words, then we increment top 3 match count.\n","\n","&emsp;&emsp;&emsp;&emsp;&emsp;So in our example the targets words are subset of words attended by BERT i-e, <br>\n","\n","&emsp;&emsp;&emsp;&emsp;&emsp; target <= attended_words[:3] <br>\n","&emsp;&emsp;&emsp;&emsp;&emsp; i-e {'hame'}<={'hame', 'early', 'came'} <br>\n","&emsp;&emsp;&emsp;&emsp;&emsp;So we increment, top_3_match.<br>\n","<br>\n","<b>top_3_match_accuracy</b> = top_3_match / num_predictions\n","<br>\n","\n","<b> jaccard_sim </b> = Jaccard sim, of target words and attended words.\n","\n","&emsp;&emsp;&emsp;&emsp;&emsp; jaccard_sim = len( target & attended_words[:len(target)] ) / len( target U attended_words[:len(target)] ) <br>\n","\n","&emsp;&emsp;&emsp;&emsp;&emsp;So in our example,  jaccard_sim = 1<br>\n","&emsp;&emsp;&emsp;&emsp;&emsp; Since, len({'hame'} & {'hame'}) / len({'hame'} U {'hame'}) = 1\n","\n","<br>\n","<b> jaccard_match </b>= If jaccard_sim > 0.5 we increment jaccard_match.\n","<br>\n","\n","<b>jaccard_match_accuracy</b> = jaccard_match / num_predictions\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"2R0umLBPgRNb"},"source":["# Use attention weights to calculate similarity scores and accuracy\n","\n","# utilities\n","import statistics\n","\n","def multi_index(lst: List[T], indices: Iterable[int]) -> List[T]:\n","    result = []\n","    for i in indices:\n","        result.append(lst[i])\n","    return result\n","\n","\n","@dataclass\n","class Prediction:\n","    id: str\n","    target: Set[int]\n","    predictions: List[int]  # ordered but unique. From a prediction for an id\n","\n","    def top_n(self, n: Optional[int] = None) -> Set[int]:\n","        \"\"\"\n","        if n is not provided, use len(self.target)\n","        \"\"\"\n","        if n is None:\n","            n = len(self.target)\n","\n","        return set(self.predictions[:n])\n","\n","    def jaccard_similarity(self, n: Optional[int] = None) -> float:\n","        \"\"\"\n","        if n is not provided, use len(self.target)\n","        \"\"\"\n","        if n is None:\n","            n = len(self.target)\n","\n","        return len(self.target & self.top_n(n)) / len(self.target | self.top_n(n))\n","    \n","    \n","@dataclass\n","class EvalStrategyResult:\n","    exact_match_accuracy: float = 0\n","    jaccard_match_accuracy: float = 0\n","    mean_jaccard_similarity: float = 0\n","    top_3_match_accuracy: float = 0"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zVZDTRBRgRNb"},"source":["Strategy = Literal[\"sum\", \"max\"]\n","\n","def get_best_choices(attn: np.ndarray, strategy: Strategy) -> List[int]:\n","    \"\"\"\n","        \n","    \"\"\"\n","    heads, words = attn.shape\n","    assert heads == 12\n","\n","    if strategy == \"sum\":\n","        attn = attn.sum(axis=0)\n","    elif strategy == \"max\":\n","        attn = attn.max(axis=0)  # prevents picking the same word twice\n","    else:\n","        raise ValueError(strategy)\n","\n","    assert len(attn) == words, f\"should be {words} different options; got {len(attn)}\"\n","\n","    indices = attn.argsort()[::-1]  # gets indices from max attention to min attention\n","    best_choices: List[int] = indices.tolist()\n","\n","    # filter first and last word because it's [CLS] and [SEP]\n","    best_choices.remove(0)  # [CLS]\n","    best_choices.remove(max(best_choices))  # [SEP]\n","\n","    return best_choices\n","\n","def get_universal_correct_predictions(weights_filename: str) -> Set[str]:\n","    \"\"\"\n","        returns sentence id for which all the models give correct predictions.\n","    \"\"\"\n","    bert_correct_predictions = set()\n","\n","    bert_cache = load_model_cache(\"bert\", weights_filename)\n","    for sent_id, (_, _, prediction) in bert_cache.items():\n","        if prediction:\n","            bert_correct_predictions.add(sent_id)\n","\n","    roberta_correct_predictions = set()\n","\n","    roberta_cache = load_model_cache(\"roberta\", weights_filename)\n","    for sent_id, (_, _, prediction) in roberta_cache.items():\n","        if prediction:\n","            roberta_correct_predictions.add(sent_id)\n","\n","    scibert_correct_predictions = set()\n","\n","    scibert_cache = load_model_cache(\"scibert\", weights_filename)\n","    for sent_id, (_, _, prediction) in scibert_cache.items():\n","        if prediction:\n","            scibert_correct_predictions.add(sent_id)\n","\n","    universal = (\n","        bert_correct_predictions\n","        & scibert_correct_predictions\n","        & roberta_correct_predictions\n","    )\n","\n","    assert len(universal) <= len(bert_correct_predictions)\n","    assert len(universal) <= len(scibert_correct_predictions)\n","    assert len(universal) <= len(roberta_correct_predictions)\n","\n","    return universal\n","\n","def get_random_predictions(edits: List[Edit]) -> List[Prediction]:\n","    \"\"\"\n","        a random model which just gives attention to words in random fashion.\n","    \"\"\"\n","    random.seed(42)\n","\n","    results = []\n","\n","    for edit in edits:\n","\n","        possible_indices = list(\n","            range(1, len(edit.words) - 1)\n","        )  # 1 to skip [CLS], len(edit.words)-1 to skip [SEP]\n","        random.shuffle(possible_indices)\n","        assert 0 not in possible_indices\n","        assert len(edit.words) - 1 not in possible_indices\n","        best_word_predictions = possible_indices\n","\n","        target_words = multi_index(edit.words, edit.best_words)\n","        assert \"[CLS]\" not in target_words, edit\n","        assert \"[SEP]\" not in target_words, edit\n","\n","        if not target_words:\n","            continue\n","\n","        predicted_words = multi_index(edit.words, best_word_predictions)\n","        assert \"[CLS]\" not in predicted_words, best_word_predictions\n","        assert \"[SEP]\" not in predicted_words, best_word_predictions\n","\n","        results.append(Prediction(edit.id, edit.best_words, best_word_predictions))\n","\n","    return results\n","\n","def cls_attn(last_layer_attn: np.ndarray) -> np.ndarray:\n","    \"\"\"\n","        extract attention given by \"[CLS]\" sub string to all other substrings\n","    \"\"\"\n","    heads, words_from, words_to = last_layer_attn.shape\n","    assert heads == 12, heads\n","    assert words_from == words_to\n","\n","    # [:, 0, :] picks the [CLS] token's attention to all words for all heads\n","    return last_layer_attn[:, 0, :]\n","\n","def use_strategy(\n","    edits: List[Edit], strategy: Strategy, attn_cache: Cache,\n",") -> List[Prediction]:\n","    \n","    \"\"\"\n","       returns actual target words which need edition and word to which we paid attention during prediction.\n","       \n","    \"\"\"\n","    results = []\n","\n","    for edit in edits:\n","        if edit.id not in attn_cache:\n","            continue  # tokenization error\n","        words, attn, prediction = attn_cache[edit.id]\n","\n","        assert words == edit.words, f\"{words} != {edit.words}\"\n","\n","        best_word_predictions = get_best_choices(cls_attn(attn), strategy)\n","\n","        target_words = multi_index(words, edit.best_words)\n","        assert \"[CLS]\" not in target_words, edit\n","        assert \"[SEP]\" not in target_words, edit\n","\n","        predicted_words = multi_index(words, best_word_predictions)\n","        assert \"[CLS]\" not in predicted_words, best_word_predictions\n","        assert \"[SEP]\" not in predicted_words, best_word_predictions\n","        \n","        if len(edit.best_words) >0:\n","            results.append(Prediction(edit.id, edit.best_words, best_word_predictions))\n","\n","    return results\n","\n","\n","def evaluate_strategy(predictions: List[Prediction]) -> EvalStrategyResult:\n","    \"\"\"\n","        returns tuple of metrics \n","        \n","        Calculate following metrics:\n","        \n","        exact_match_accuracy \n","        jaccard_match_accuracy \n","        statistics.mean(jaccard_sims) \n","        top_3_accuracy \n","                \n","    \"\"\"\n","    total = len(predictions)\n","    if not total:\n","        return EvalStrategyResult()\n","\n","    exact_matches = 0\n","    jaccard_sims = []\n","    top_3_matches = 0\n","\n","    for prediction in predictions:\n","#         print(prediction)\n","        if prediction.target == prediction.top_n():\n","            exact_matches += 1\n","\n","        if prediction.target <= prediction.top_n(3):\n","            \n","            # subset operation\n","            assert len(prediction.target) > 0\n","            top_3_matches += 1\n","\n","        jaccard_sims.append(prediction.jaccard_similarity())\n","\n","    exact_match_accuracy = exact_matches / total\n","    top_3_accuracy = top_3_matches / total\n","\n","    jaccard_match_accuracy = len([s for s in jaccard_sims if s >= 0.5]) / total\n","\n","    return EvalStrategyResult(\n","        exact_match_accuracy,\n","        jaccard_match_accuracy,\n","        statistics.mean(jaccard_sims),\n","        top_3_accuracy,\n","    )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XFVWC3fzgRNc"},"source":["\n","def evaluate_all_strategies_on_spelling_edits() -> None:\n","    \"\"\"\n","        saves scores calculated by both \"sum\" and \"max\" strategy for each model in a json file.\n","    \n","    \"\"\"\n","    spelling_edits = get_edits_with_only_spelling_errors()\n","\n","    all_strategies: List[Strategy] = [\"sum\", \"max\"]\n","\n","    skip_false_predictions_models = [\n","        \"bert\",\n","        \"scibert\",\n","        \"roberta\",\n","        \"bert_default\",\n","#         \"bert_glue\",\n","    ]\n","\n","    scores: List[Score] = []\n","    \n","    # get sentence id to which all the models gave correct prediction\n","    universal = get_universal_correct_predictions(SPELLING_EDIT_WEIGHTS_FILENAME)\n","\n","    for model_name in skip_false_predictions_models:\n","        # load the weights for a model\n","        cache = load_model_cache(model_name, SPELLING_EDIT_WEIGHTS_FILENAME)\n","\n","        # analyse only those predictions that all models get correct.\n","        cache = {key: value for key, value in cache.items() if key in universal}\n","\n","        # for each strategy and type of edit, make a bunch of guesses\n","        for strategy in all_strategies:\n","            # for each prediction get a tuple containing pred id target words and \n","            # words to which we gave attention in sorted fashion \n","            predictions = use_strategy(spelling_edits, strategy, cache,)\n","            \n","            # calculate metrics\n","            result = evaluate_strategy(predictions)\n","            \n","            # store calculated metrics in a list\n","            scores.append(\n","                Score(\n","                    model_name,\n","                    strategy,\n","                    result.exact_match_accuracy,\n","                    result.jaccard_match_accuracy,\n","                    result.mean_jaccard_similarity,\n","                    result.top_3_match_accuracy,\n","                    False,\n","                )\n","            )\n","\n","    random_predictions = get_random_predictions(spelling_edits)\n","\n","    result = evaluate_strategy(random_predictions)\n","\n","    scores.append(\n","        Score(\n","            \"random\",\n","            \"sum\",\n","            result.exact_match_accuracy,\n","            result.jaccard_match_accuracy,\n","            result.mean_jaccard_similarity,\n","            result.top_3_match_accuracy,\n","            False,\n","        )\n","    )\n","\n","    scores.append(\n","        Score(\n","            \"random\",\n","            \"max\",\n","            result.exact_match_accuracy,\n","            result.jaccard_match_accuracy,\n","            result.mean_jaccard_similarity,\n","            result.top_3_match_accuracy,\n","            False,\n","        )\n","    )\n","\n","    with open(\n","        \"./data-unversioned/attention-weights/scores/spelling-edit.json\", \"w\"\n","    ) as file:\n","        json.dump(scores, file, indent=4, cls=ScoreEncoder)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JxYFkzvVgRNc"},"source":["from dataclasses import dataclass\n","from typing import Any, Optional\n","\n","\n","\n","@dataclass\n","class Score:\n","    model_name: str\n","    strategy: Strategy\n","    exact_match_accuracy: float\n","    jaccard_match_accuracy: float\n","    avg_jaccard_similarity: float\n","    top_3_match_accuracy: float\n","    skipped_false_predictions: bool\n","\n","    @staticmethod\n","    def parse(dct: Any) -> Optional[\"Score\"]:\n","        if \"__Score__\" in dct and dct[\"__Score__\"]:\n","            # parse it\n","            return Score(\n","                dct[\"model name\"],\n","                dct[\"strategy\"],\n","                dct[\"exact match accuracy\"],\n","                dct[\"jaccard match accuracy\"],\n","                dct[\"avg jaccard similarity\"],\n","                dct[\"top 3 match accuracy\"],\n","                dct[\"skipped false predictions\"],\n","            )\n","        else:\n","            return None\n","\n","\n","class ScoreEncoder(json.JSONEncoder):\n","    def default(self, o: Any) -> Any:\n","        if not isinstance(o, Score):\n","            return super().default(o)\n","\n","        return {\n","            \"__Score__\": True,\n","            \"model name\": o.model_name,\n","            \"strategy\": o.strategy,\n","            \"exact match accuracy\": o.exact_match_accuracy,\n","            \"jaccard match accuracy\": o.jaccard_match_accuracy,\n","            \"avg jaccard similarity\": o.avg_jaccard_similarity,\n","            \"top 3 match accuracy\": o.top_3_match_accuracy,\n","            \"skipped false predictions\": o.skipped_false_predictions,\n","        }\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1SBzjofkgRNc"},"source":["evaluate_all_strategies_on_spelling_edits()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fGM9xtK8gRNc"},"source":["def evaluate_all_strategies_on_delete_edits() -> None:\n","    delete_edits = get_edits_with_only_deleted_words()\n","\n","    all_strategies: List[predict.Strategy] = [\"sum\", \"max\"]\n","\n","    skip_false_predictions_models = [\n","        \"bert\",\n","        \"scibert\",\n","        \"roberta\",\n","        \"bert_default\",\n","#         \"bert_glue\",\n","    ]\n","\n","    scores: List[Score] = []\n","\n","    universal = get_universal_correct_predictions(DELETE_EDIT_WEIGHTS_FILENAME)\n","\n","    for model_name in skip_false_predictions_models:\n","        # load the weights for a model\n","        cache = load_model_cache(model_name, DELETE_EDIT_WEIGHTS_FILENAME)\n","\n","        # only do predictions that all models get\n","        cache = {key: value for key, value in cache.items() if key in universal}\n","\n","        # for each strategy and type of edit, make a bunch of guesses\n","        for strategy in all_strategies:\n","\n","            predictions = use_strategy(delete_edits, strategy, cache)\n","\n","            result = evaluate_strategy(predictions)\n","\n","            scores.append(\n","                Score(\n","                    model_name,\n","                    strategy,\n","                    result.exact_match_accuracy,\n","                    result.jaccard_match_accuracy,\n","                    result.mean_jaccard_similarity,\n","                    result.top_3_match_accuracy,\n","                    False,\n","                )\n","            )\n","\n","    random_predictions = get_random_predictions(delete_edits)\n","\n","    result = evaluate_strategy(random_predictions)\n","\n","    scores.append(\n","        Score(\n","            \"random\",\n","            \"sum\",\n","            result.exact_match_accuracy,\n","            result.jaccard_match_accuracy,\n","            result.mean_jaccard_similarity,\n","            result.top_3_match_accuracy,\n","            False,\n","        )\n","    )\n","\n","    scores.append(\n","        Score(\n","            \"random\",\n","            \"max\",\n","            result.exact_match_accuracy,\n","            result.jaccard_match_accuracy,\n","            result.mean_jaccard_similarity,\n","            result.top_3_match_accuracy,\n","            False,\n","        )\n","    )\n","\n","    with open(\n","        \"./data-unversioned/attention-weights/scores/delete-edit.json\", \"w\"\n","    ) as file:\n","        json.dump(scores, file, indent=4, cls=ScoreEncoder)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"i0WSo_DMgRNd"},"source":["evaluate_all_strategies_on_delete_edits()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nTQQoZ67gRNd"},"source":["## 3.4 Plotting scores"]},{"cell_type":"code","metadata":{"id":"M-wUs99ZgRNd"},"source":["SPELLING_SCORES_FILE = \"spelling-edit.json\"\n","INTERPRETABILITY_FOLDER = Path(\"./data-unversioned/attention-weights/\")\n","SCORES_FOLDER = INTERPRETABILITY_FOLDER / \"scores\"\n","DELETE_SCORES_FILE = \"delete-edit.json\"\n","\n","def get_scores(filename: str) -> List[Score]:\n","    assert filename.endswith(\".json\")\n","\n","    with open(SCORES_FOLDER / filename) as file:\n","        score_dict_list = json.load(file)\n","\n","    parsed = [Score.parse(score) for score in score_dict_list]\n","    return [s for s in parsed if s]\n","\n","def get_relevant_scores(\n","    scores: List[Score],\n",") -> Tuple[Score, Score, Score, Score, Score, Score]:\n","    \"\"\"\n","    returns a list of scores for\n","    * Random\n","    * BERT_default-sum\n","    * BERT_GLUE-sum\n","    * BERT-sum\n","    * SciBERT-sum\n","    * RoBERTA-sum\n","    \"\"\"\n","\n","    random = next(score for score in scores if score.model_name == \"random\")\n","\n","    bert_default_sum = next(\n","        score\n","        for score in scores\n","        if score.model_name == \"bert_default\" and score.strategy == \"sum\"\n","    )\n","\n","#     bert_glue_sum = next(\n","#         score\n","#         for score in scores\n","#         if score.model_name == \"bert_glue\" and score.strategy == \"sum\"\n","#     )\n","\n","    bert_sum = next(\n","        score\n","        for score in scores\n","        if score.model_name == \"bert\" and score.strategy == \"sum\"\n","    )\n","\n","    scibert_sum = next(\n","        score\n","        for score in scores\n","        if score.model_name == \"scibert\" and score.strategy == \"sum\"\n","    )\n","\n","    roberta_sum = next(\n","        score\n","        for score in scores\n","        if score.model_name == \"roberta\" and score.strategy == \"sum\"\n","    )\n","\n","#     return (random, bert_default_sum, bert_glue_sum, bert_sum, scibert_sum, roberta_sum)\n","    return (random, bert_default_sum, bert_sum, scibert_sum, roberta_sum)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1gyt3XBSgRNd"},"source":["spell_scores = get_relevant_scores(get_scores(SPELLING_SCORES_FILE))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9r6PDonugRNe"},"source":["del_scores = get_relevant_scores(get_scores(DELETE_SCORES_FILE))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a5PT-TRAgRNe","outputId":"ee9f251d-66a0-4e11-b1fa-7ac725389190"},"source":["# plotting functions\n","\n","from typing import Collection\n","import matplotlib.pyplot as plt\n","\n","# region colors\n","\n","BLACK = \"k\"\n","GREEN = \"#59d98e\"\n","SEA = \"#159d82\"\n","BLUE = \"#3498db\"\n","PURPLE = \"#9b59b6\"\n","GREY = \"#95a5a6\"\n","RED = \"#e74c3c\"\n","ORANGE = \"#f39c12\"\n","\n","def model_name_to_model_and_dataset(model_name: str) -> Tuple[str, str]:\n","    model_name = model_name.lower()\n","    if model_name == \"bert_default\":\n","        return \"BERT\", \"n/a\"\n","#     elif model_name == \"bert_glue\":\n","#         return \"BERT\", \"GLUE\"\n","    elif model_name == \"bert\":\n","        return \"BERT\", \"AESW\"\n","    elif model_name == \"roberta\":\n","        return \"RoBERTA\", \"AESW\"\n","    elif model_name == \"scibert\":\n","        return \"SciBERT\", \"AESW\"\n","    elif model_name == \"random\":\n","        return \"Random\", \"\"\n","    else:\n","        raise ValueError(f\"{model_name} is not a valid name\")\n","\n","def format_x_label(name: str, data: str) -> str:\n","    if data:\n","        return f\"{name}\\n({data})\"\n","    else:\n","        return name\n","\n","\n","def plot_n_bars(\n","    x: Collection[str], y_points: Collection[Iterable[float]], y_labels: Collection[str]\n",") -> None:\n","    width = 0.7 / len(y_points)  # the width of the bars\n","\n","    x_pos = np.arange(len(x))\n","\n","    fig, ax = plt.subplots()\n","\n","    colors = [SEA, ORANGE, BLUE]\n","    rects = []\n","    for i, (y, c) in enumerate(zip(y_points, colors)):\n","        rects.append(ax.bar(x_pos + i * width, y, width, color=c)[0])\n","\n","    ax.set_ylabel(\"Top 3 Match Accuracy\")\n","    ax.set_xticks(x_pos + (len(y_points) / 2 - 0.5) * width)\n","    ax.set_xticklabels(x)\n","    ax.legend(rects, y_labels)\n","\n","    fig.tight_layout()\n","\n","\n","\n","points = [\n","        (\n","            format_x_label(\n","                *model_name_to_model_and_dataset(spell_score.model_name)\n","            ),\n","            spell_score.top_3_match_accuracy,\n","            del_score.top_3_match_accuracy,\n","        )\n","        for spell_score, del_score in zip(spell_scores, del_scores)\n","    ]\n","\n","xlabels, y_spelling, y_delete = zip(*points)\n","\n","plot_n_bars(\n","    xlabels, (y_spelling, y_delete), (\"spelling error\", \"deleted words\"),\n",")\n","\n","plt.show()\n"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"uQOOoYkxgRNe"},"source":["## Comparing attentions of each model"]},{"cell_type":"code","metadata":{"id":"2ESAiYwigRNf"},"source":["# Create individual plots comparing each model's attention on a single sentence"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RCj22lflgRNf"},"source":["import matplotlib\n","\n","def plot_cls_attention(\n","    tokens: List[str], attn: np.ndarray, title: str, word_ticks: bool, ax: Any = None\n",") -> Any:\n","    # https://matplotlib.org/3.1.1/gallery/images_contours_and_fields/image_annotated_heatmap.html\n","    heads = list(range(12))\n","\n","    if not ax:\n","        ax = plt.gca()\n","\n","    im = ax.imshow(\n","        attn.T, cmap=\"Reds\", norm=matplotlib.colors.Normalize(vmin=0.0, vmax=1.0)\n","    )\n","\n","    ax.set_xticks(np.arange(len(heads)))\n","    ax.set_xticklabels([])\n","    ax.set_xlabel(\"Attention Heads\")\n","\n","    if word_ticks:\n","        ax.set_yticks(np.arange(len(tokens)))\n","        ax.set_yticklabels(tokens, size=12)\n","    else:\n","        ax.set_yticks([])\n","        ax.set_yticklabels([])\n","\n","    for edge, spine in ax.spines.items():\n","        spine.set_visible(False)\n","\n","    ax.set_title(title)\n","    return im\n","\n","def plot_word_level_attention(\n","    sent: str,\n","    cls_model: SentenceClassificationModel,\n","    model: PreTrainedModel,\n","    tokenizer: PreTrainedTokenizerFast,\n","    title: str,\n","    word_ticks: bool,\n","    **plotkwargs: Any,\n",") -> Any:\n","    output = get_words_and_attention_and_prediction(\n","        [sent], cls_model, model, tokenizer\n","    )[0]\n","\n","    title += f\" ({'needs edit' if output.prediction else 'no edit'})\"\n","\n","    return plot_cls_attention(\n","        output.words, cls_attn(output.attention), title, word_ticks, **plotkwargs\n","    )\n","\n","\n","def plot_all_word_models(sentence: str) -> None:\n","    height = 2 + 0.2 * len(tokenize_transformer_sentences(sentence))\n","    fig, axes = plt.subplots(1, 3, figsize=(12, height), constrained_layout=True)\n","\n","    ((ax1, ax2, ax3)) = axes\n","\n","    bert_cls, bert, bert_tokenizer = load_bert()\n","\n","    im = plot_word_level_attention(\n","        sentence, bert_cls, bert, bert_tokenizer, title=\"BERT\", word_ticks=True, ax=ax1\n","    )\n","\n","    scibert_cls, scibert, scibert_tokenizer = load_scibert()\n","\n","    im = plot_word_level_attention(\n","        sentence,\n","        scibert_cls,\n","        scibert,\n","        scibert_tokenizer,\n","        title=\"SciBERT\",\n","        word_ticks=False,\n","        ax=ax2,\n","    )\n","\n","    roberta_cls, roberta, roberta_tokenizer = load_roberta()\n","\n","    im = plot_word_level_attention(\n","        sentence,\n","        roberta_cls,\n","        roberta,\n","        roberta_tokenizer,\n","        title=\"RoBERTa\",\n","        word_ticks=False,\n","        ax=ax3,\n","    )\n","\n","    # fig.tight_layout()\n","\n","    cbar = fig.colorbar(\n","        im,\n","        ax=axes.ravel().tolist(),\n","        orientation=\"horizontal\",\n","        aspect=30,\n","        use_gridspec=True,\n","    )\n","    cbar.ax.set_xlabel(\"Attention\", va=\"center\")\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XxdxWHxPgRNf","outputId":"4ae56667-e249-4741-9fb5-a02bd1194e20"},"source":["plot_all_word_models(\"This allows us to observe Saturn's moons.\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 864x302.4 with 4 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"mwahfxKHgRNf","outputId":"17a63b2a-a89f-423c-b362-fe91285b99e7"},"source":["plot_all_word_models(\"The algorithm descripted in the previous sections has several advantages.\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 864x331.2 with 4 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"k_7QgyyVgRNg"},"source":["## Compare fine tuned BERT with default BERT"]},{"cell_type":"code","metadata":{"id":"0fC40KYxgRNg"},"source":["def plot_finetuned_models_comparison(sentence: str) -> None:\n","    height = 2 + 0.2 * len(tokenize_transformer_sentences(sentence))\n","    fig, axes = plt.subplots(1, 2, figsize=(12, height), constrained_layout=True)\n","\n","    ((ax1, ax2)) = axes\n","\n","    bert_default_cls, bert_default, bert_default_tokenizer = load_bert_default()\n","\n","    im = plot_word_level_attention(\n","        sentence,\n","        bert_default_cls,\n","        bert_default,\n","        bert_default_tokenizer,\n","        title=\"Before\",\n","        word_ticks=True,\n","        ax=ax1,\n","    )\n","\n","    bert_cls, bert, bert_tokenizer = load_bert()\n","\n","    im = plot_word_level_attention(\n","        sentence,\n","        bert_cls,\n","        bert,\n","        bert_tokenizer,\n","        word_ticks=False,\n","        title=\"After\",\n","        ax=ax2,\n","    )\n","\n","    # fig.tight_layout()\n","\n","    cbar = fig.colorbar(\n","        im,\n","        ax=axes.ravel().tolist(),\n","        orientation=\"horizontal\",\n","        aspect=30,\n","        use_gridspec=True,\n","    )\n","    cbar.ax.set_xlabel(\"Attention\", va=\"center\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MTgSLKT6gRNg","outputId":"b34e6f63-8362-4b47-9078-98d25730f4fb"},"source":["plot_finetuned_models_comparison(\"The algorithm descripted in the previous sections has several advantages.\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 864x331.2 with 3 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"yd1IB3u8gRNg"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NZFZ6dZdgRNh"},"source":[""],"execution_count":null,"outputs":[]}]}